[comment encoding = UTF-8 /]
[module generateSparkApplication('http://www.eclipse.org/emf/2002/Ecore', 'http://www.eclipse.org/uml2/5.0.0/UML')]

[import streamgen::main::queryUtils /]
[import streamgen::spark::generateSparkSources/]
[import streamgen::spark::generateSparkTransformations/]
[import streamgen::spark::generateSparkSinks/]

[template public generateSparkApplication(aModel : Model)]

[file (aModel.name.toLower().concat('/application/').concat(aModel.name.concat('.java')), false, 'UTF-8')]
package [aModel.name.toLower().concat('.application')/];

[for (p:Package | aModel.eContents(Package)) ]
  [if hasStereotype(p, 'StreamDatatypes')]
     [for (subc:DataType | p.eContents(DataType)) ]
import [aModel.name.toLower()/].datatypes.[subc.name/];
    [/for]
  [/if]
[/for]

[for (c:Class | aModel.eContents(Class)) ]
  [if c.getAppliedStereotypes()->asSequence()->exists(s | s.name.strstr('Transformation') and not (s.name = 'FilterTransformation') and not (s.name = 'SumTransformation'))]
import [aModel.name.toLower()/].functions.[c.name/];
  [/if]
[/for]

import org.apache.log4j.Level;
import org.apache.log4j.Logger;
import scala.Tuple2;
import org.apache.spark.*;
import org.apache.spark.api.java.*;
import org.apache.spark.streaming.*;
import org.apache.spark.streaming.api.java.*;
import org.apache.spark.api.java.function.*;
import java.util.*;
import org.apache.spark.api.java.Optional;

[if (aModel.eAllContents(Class) -> exists(c |hasStereotype(c, 'KafkaSink')))]
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.common.serialization.StringDeserializer;
[/if]

[if (aModel.eAllContents(Class) -> exists(c | hasStereotype(c, 'KafkaSource')))]
import org.apache.spark.streaming.kafka010.*;
[/if]

[if (aModel.eAllContents(Class) -> exists(c | hasStereotype(c, 'CassandraSink')))]
import static com.datastax.spark.connector.japi.CassandraJavaUtil.*;
[/if]



public class [aModel.name/] {

    public static void main(String['['/][']'/] args) throws Exception {

	   Logger.getLogger("org").setLevel(Level.OFF);
	   Logger.getLogger("akka").setLevel(Level.OFF);
	
	   SparkConf conf = new SparkConf().setMaster("local[ '[' /]2[ ']' /]").setAppName("[aModel.name/]");
	   JavaStreamingContext jssc = new JavaStreamingContext(conf, [if getStereotypeProperty(aModel, 'SparkApplication', 'microBatchSize').oclIsUndefined()]Durations.seconds(1)[else]Durations.[getStereotypeProperty(aModel, 'SparkApplication', 'microBatchSize').eGet('timeUnit').toString().toLower()/]([getStereotypeProperty(aModel, 'SparkApplication', 'microBatchSize').eGet('size')/])[/if]);



[for (c:Class | aModel.eContents(Class)) ]
    [if hasStereotype(c, 'SocketSource')]  
		[generateSparkSocketSource(c)/]
    [elseif hasStereotype(c, 'TextFileSource')]  
		[generateSparkTextFileSource(c)/]
    [elseif hasStereotype(c, 'KafkaSource')]  
		[generateSparkKafkaSource(c)/]
    [elseif hasStereotype(c, 'KafkaSink')]  
		[generateSparkKafkaSink(c)/]
    [elseif hasStereotype(c, 'MapTransformation')]  
		[generateSparkMapTransformation(c)/]
    [elseif hasStereotype(c, 'FilterTransformation')]  
		[generateSparkFilterTransformation(c)/]
	[elseif hasStereotype(c, 'FlatmapTransformation')]
		[generateSparkFlatmapTransformation(c)/]
    [elseif hasStereotype(c, 'TextFileSink')]
		[generateSparkTextFileSink(c)/]
    [elseif hasStereotype(c, 'CassandraSink')]
		[generateSparkCassandraSink(c)/]
    [elseif hasStereotype(c, 'WindowTransformation')]
		[generateSparkWindowTransformation(c)/]
    [elseif hasStereotype(c, 'SumTransformation')]
		[generateSparkSumTransformation(c)/]
	[else]
    [/if]
[/for]

		jssc.start(); // Start the computation
		jssc.awaitTermination(); // Wait for the computation to terminate
    }
}
[/file]
[/template]