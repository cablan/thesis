[comment encoding = UTF-8 /]
[module generateSparkSinks('http://www.eclipse.org/emf/2002/Ecore', 'http://www.eclipse.org/uml2/5.0.0/UML')]

[import streamgen::main::queryUtils/]

[template public generateSparkTextFileSink(aClass : Class)]
       [getInputNames()->first()/]
		.dstream().saveAsTextFiles("[getStereotypeProperty(aClass, 'TextFileSink', 'filepath').toString().substring(1, getStereotypeProperty(aClass, 'TextFileSink', 'filepath').toString().size()-4)/]"
					, "[getStereotypeProperty(aClass, 'TextFileSink', 'filepath').toString().substring(getStereotypeProperty(aClass, 'TextFileSink', 'filepath').toString().size()-2, getStereotypeProperty(aClass, 'TextFileSink', 'filepath').toString().size())/]");
[/template]

[template public generateSparkKafkaSink(aClass : Class)]

	   Map<String, Object> [aClass.name.toString().concat('_kafkaParams')/] = new HashMap<>();
	   [aClass.name.toString().concat('_kafkaParams')/].put("bootstrap.servers", "[getStereotypeProperty(aClass, 'KafkaSink', 'kafkaBrokerIp')/]:[getStereotypeProperty(aClass, 'KafkaSink', 'kafkaBrokerPort')/]");
	   [aClass.name.toString().concat('_kafkaParams')/].put("key.deserializer", StringDeserializer.class);
	   [aClass.name.toString().concat('_kafkaParams')/].put("value.deserializer", StringDeserializer.class);
	   [aClass.name.toString().concat('_kafkaParams')/].put("group.id", "[aClass.name.toString().concat('_groupId')/]");
	   [aClass.name.toString().concat('_kafkaParams')/].put("auto.offset.reset", "latest");
	   [aClass.name.toString().concat('_kafkaParams')/].put("enable.auto.commit", false);

       [getInputNames()->first()/].foreachRDD(rdd ->
       rdd.foreachPartition(partition -> {

    	   while(partition.hasNext()) {
                 KafkaProducer producer = new KafkaProducer<String, String>([aClass.name.toString().concat('_kafkaParams')/]);
                 ProducerRecord<String, String> message=new ProducerRecord<String, String>("[aClass.name/]",null,partition.next().toString());
                 producer.send(message);	    		   
    	   }
       }
       ));
[/template]

[template public generateSparkCassandraSink(aClass : Class)]
       [getInputNames()->first()/].foreachRDD(rdd ->
       		javaFunctions(rdd).writerBuilder("[getInputNames()->first().toString().concat('_keyspace')/]", "[getInputNames()->first().toString()/]", mapToRow([getInputsConveyed(aClass)-> first()/].class)).saveToCassandra());  
[/template]